{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d158d9fb",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "This notebook demonstrates a scalable bioinformatics workflow for analyzing **rare loss-of-function (LoF) variants** across samples and genes.  \n",
    "It uses [**Narwhals**](https://github.com/narwhals-dev/narwhals/) — a **unified dataframe API** — to write code once and run seamlessly on either **Polars** (fast, efficient) or **Pandas** (flexible, widely used).\n",
    "\n",
    "The goal of this pipeline is to:\n",
    "1. **Read** variant call data from `.tsv` or `.parquet` files.\n",
    "2. **Filter** variants to identify rare LoF events based on allele frequency (`AF`) thresholds.\n",
    "3. **Annotate** variants into frequency buckets (`ultra_rare`, `rare`, `common`).\n",
    "4. **Aggregate** per-sample, per-gene burden counts.\n",
    "5. **Pivot** the data into a **sample × gene burden matrix**.\n",
    "6. **Join** with sample metadata to generate a final **design matrix** for downstream modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/katwre/projects/Data_engineering-projects/narwhals_data_pipeline/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import narwhals as nw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c6655",
   "metadata": {},
   "source": [
    "### Create sample input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626ccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated variants.tsv (~1,000 rows) and sample_metadata.tsv (~50 rows).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_samples = 50\n",
    "n_genes = 30\n",
    "n_variants = 1000\n",
    "\n",
    "# Define possible genes and impacts\n",
    "genes = [f\"GENE{i}\" for i in range(1, n_genes + 1)]\n",
    "impacts = [\"stop_gained\", \"frameshift_variant\", \"splice_donor_variant\",\n",
    "           \"missense_variant\", \"synonymous_variant\"]\n",
    "consequences = {\"stop_gained\": \"high\", \"frameshift_variant\": \"high\",\n",
    "                \"splice_donor_variant\": \"high\", \"missense_variant\": \"moderate\",\n",
    "                \"synonymous_variant\": \"low\"}\n",
    "\n",
    "# Generate sample IDs\n",
    "sample_ids = [f\"S{i:03d}\" for i in range(1, n_samples + 1)]\n",
    "\n",
    "# Generate variants table\n",
    "variants = pd.DataFrame({\n",
    "    \"sample_id\": np.random.choice(sample_ids, n_variants),\n",
    "    \"gene\": np.random.choice(genes, n_variants),\n",
    "    \"impact\": np.random.choice(impacts, n_variants, p=[0.1, 0.15, 0.1, 0.5, 0.15]),\n",
    "    \"AF\": np.round(np.random.beta(0.5, 10, n_variants), 5)  # skewed towards rare variants\n",
    "})\n",
    "variants[\"consequence\"] = variants[\"impact\"].map(consequences)\n",
    "\n",
    "# Save variants file\n",
    "variants.to_csv(\"./input_data/variants.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Generate sample metadata\n",
    "metadata = pd.DataFrame({\n",
    "    \"sample_id\": sample_ids,\n",
    "    \"cohort\": np.random.choice([\"Discovery\", \"Validation\", \"Replication\"], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "    \"sex\": np.random.choice([\"F\", \"M\"], n_samples),\n",
    "    \"age\": np.random.randint(35, 80, n_samples)\n",
    "})\n",
    "metadata.to_csv(\"./input_data/sample_metadata.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"✅ Generated variants.tsv (~1,000 rows) and sample_metadata.tsv (~50 rows).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cohort_variants.parquet created successfully!\n",
      "  sample_id    gene              impact       AF consequence\n",
      "0      S039  GENE28    missense_variant  0.07361    moderate\n",
      "1      S029  GENE18  frameshift_variant  0.00102        high\n",
      "2      S015   GENE4         stop_gained  0.00097        high\n",
      "3      S043  GENE13    missense_variant  0.04071    moderate\n",
      "4      S008   GENE4    missense_variant  0.05094    moderate\n"
     ]
    }
   ],
   "source": [
    "# Generate cohort_variants.parquet\n",
    "\n",
    "# Create random variants DataFrame\n",
    "np.random.seed(42)\n",
    "variants_df = pd.DataFrame({\n",
    "    \"sample_id\": np.random.choice(sample_ids, n_variants),\n",
    "    \"gene\": np.random.choice(genes, n_variants),\n",
    "    \"impact\": np.random.choice(impacts, n_variants, p=[0.1, 0.15, 0.1, 0.5, 0.15]),\n",
    "    \"AF\": np.round(np.random.beta(0.5, 10, n_variants), 5),\n",
    "})\n",
    "variants_df[\"consequence\"] = variants_df[\"impact\"].map(consequences)\n",
    "\n",
    "\n",
    "# Convert to Arrow Table\n",
    "table = pa.Table.from_pandas(variants_df)\n",
    "\n",
    "# Save as Parquet\n",
    "pq.write_table(table, \"./input_data/cohort_variants.parquet\")\n",
    "\n",
    "print(\"✅ cohort_variants.parquet created successfully!\")\n",
    "#print(variants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbeed9",
   "metadata": {},
   "source": [
    "## One codebase, multiple engines (pandas ↔ polars)\n",
    "What this shows: a single import path and IO that target your chosen engine without branching logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0acf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variants shape: (1000, 5)\n",
      "Samples shape: (50, 4)\n",
      "Variants head:\n",
      "┌───────────────────────────────────────────────────────────────────┐\n",
      "|                        Narwhals DataFrame                         |\n",
      "|-------------------------------------------------------------------|\n",
      "|shape: (5, 5)                                                      |\n",
      "|┌───────────┬────────┬────────────────────┬─────────┬─────────────┐|\n",
      "|│ sample_id ┆ gene   ┆ impact             ┆ AF      ┆ consequence │|\n",
      "|│ ---       ┆ ---    ┆ ---                ┆ ---     ┆ ---         │|\n",
      "|│ str       ┆ str    ┆ str                ┆ f64     ┆ str         │|\n",
      "|╞═══════════╪════════╪════════════════════╪═════════╪═════════════╡|\n",
      "|│ S039      ┆ GENE25 ┆ stop_gained        ┆ 0.0     ┆ high        │|\n",
      "|│ S029      ┆ GENE1  ┆ stop_gained        ┆ 0.0282  ┆ high        │|\n",
      "|│ S015      ┆ GENE21 ┆ synonymous_variant ┆ 0.00003 ┆ low         │|\n",
      "|│ S043      ┆ GENE22 ┆ synonymous_variant ┆ 0.12123 ┆ low         │|\n",
      "|│ S008      ┆ GENE21 ┆ missense_variant   ┆ 0.01708 ┆ moderate    │|\n",
      "|└───────────┴────────┴────────────────────┴─────────┴─────────────┘|\n",
      "└───────────────────────────────────────────────────────────────────┘\n",
      "Samples head:\n",
      "┌───────────────────────────────────────┐\n",
      "|          Narwhals DataFrame           |\n",
      "|---------------------------------------|\n",
      "|shape: (5, 4)                          |\n",
      "|┌───────────┬─────────────┬─────┬─────┐|\n",
      "|│ sample_id ┆ cohort      ┆ sex ┆ age │|\n",
      "|│ ---       ┆ ---         ┆ --- ┆ --- │|\n",
      "|│ str       ┆ str         ┆ str ┆ i64 │|\n",
      "|╞═══════════╪═════════════╪═════╪═════╡|\n",
      "|│ S001      ┆ Discovery   ┆ F   ┆ 40  │|\n",
      "|│ S002      ┆ Validation  ┆ M   ┆ 71  │|\n",
      "|│ S003      ┆ Discovery   ┆ F   ┆ 65  │|\n",
      "|│ S004      ┆ Validation  ┆ F   ┆ 68  │|\n",
      "|│ S005      ┆ Replication ┆ M   ┆ 75  │|\n",
      "|└───────────┴─────────────┴─────┴─────┘|\n",
      "└───────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Flip this to \"pandas\" or \"polars\" — no other changes needed\n",
    "BACKEND = \"polars\"   # try \"pandas\" to compare\n",
    "\n",
    "# Load input files\n",
    "variants = nw.read_csv(\"./input_data/variants.tsv\", separator=\"\\t\", backend=BACKEND)\n",
    "samples  = nw.read_csv(\"./input_data/sample_metadata.tsv\",  separator=\"\\t\", backend=BACKEND)\n",
    "\n",
    "print(\"Variants shape:\", variants.shape)\n",
    "print(\"Samples shape:\", samples.shape)\n",
    "print(\"Variants head:\")\n",
    "print(variants.head())\n",
    "print(\"Samples head:\")\n",
    "print(samples.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a24d8d1",
   "metadata": {},
   "source": [
    "## Expression API that composes (portable feature engineering)\n",
    "Why unique: The same declarative expressions work across both pandas and polars through Narwhals, avoiding two codepaths or brittle .apply UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────────┐\n",
      "|          Narwhals DataFrame           |\n",
      "| Use `.to_native` to see native output |\n",
      "└───────────────────────────────────────┘\n",
      "shape: (117, 7)\n",
      "┌───────────┬────────┬──────────────────────┬─────────┬─────────────┬─────────────┬────────────┐\n",
      "│ sample_id ┆ gene   ┆ impact               ┆ AF      ┆ consequence ┆ is_rare_lof ┆ af_bucket  │\n",
      "│ ---       ┆ ---    ┆ ---                  ┆ ---     ┆ ---         ┆ ---         ┆ ---        │\n",
      "│ str       ┆ str    ┆ str                  ┆ f64     ┆ str         ┆ bool        ┆ str        │\n",
      "╞═══════════╪════════╪══════════════════════╪═════════╪═════════════╪═════════════╪════════════╡\n",
      "│ S039      ┆ GENE25 ┆ stop_gained          ┆ 0.0     ┆ high        ┆ true        ┆ ultra_rare │\n",
      "│ S003      ┆ GENE24 ┆ frameshift_variant   ┆ 0.00125 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S024      ┆ GENE23 ┆ frameshift_variant   ┆ 0.00958 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S002      ┆ GENE5  ┆ splice_donor_variant ┆ 0.00611 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S049      ┆ GENE11 ┆ stop_gained          ┆ 0.00073 ┆ high        ┆ true        ┆ rare       │\n",
      "│ …         ┆ …      ┆ …                    ┆ …       ┆ …           ┆ …           ┆ …          │\n",
      "│ S037      ┆ GENE13 ┆ frameshift_variant   ┆ 0.00392 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S028      ┆ GENE14 ┆ stop_gained          ┆ 0.00334 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S004      ┆ GENE19 ┆ stop_gained          ┆ 0.00312 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S045      ┆ GENE9  ┆ stop_gained          ┆ 0.00363 ┆ high        ┆ true        ┆ rare       │\n",
      "│ S006      ┆ GENE12 ┆ frameshift_variant   ┆ 0.00902 ┆ high        ┆ true        ┆ rare       │\n",
      "└───────────┴────────┴──────────────────────┴─────────┴─────────────┴─────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# ✅ cast using Narwhals dtype\n",
    "variants = variants.with_columns([nw.col(\"AF\").cast(nw.Float64).alias(\"AF\")])\n",
    "\n",
    "is_lof  = nw.col(\"impact\").is_in([\"stop_gained\",\"frameshift_variant\",\"splice_acceptor_variant\",\"splice_donor_variant\"])\n",
    "is_rare = nw.col(\"AF\") < 0.01\n",
    "\n",
    "af_bucket = (\n",
    "    nw.when(nw.col(\"AF\") < 1e-4).then(nw.lit(\"ultra_rare\"))\n",
    "      .otherwise(\n",
    "        nw.when(nw.col(\"AF\") < 1e-2).then(nw.lit(\"rare\"))\n",
    "          .otherwise(nw.lit(\"common\"))\n",
    "      )\n",
    ")\n",
    "\n",
    "variants_fe = (\n",
    "    variants\n",
    "    .with_columns([\n",
    "        (is_lof & is_rare).alias(\"is_rare_lof\"),\n",
    "        af_bucket.alias(\"af_bucket\"),\n",
    "    ])\n",
    "    .filter(nw.col(\"is_rare_lof\"))\n",
    ")\n",
    "\n",
    "print(variants_fe.head())\n",
    "print(variants_fe.to_native())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68833bc8",
   "metadata": {},
   "source": [
    "## GroupBy + Agg that’s backend-agnostic\n",
    "Why unique: Identical groupby semantics and naming regardless of engine; you don’t re-learn two flavors of grouping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0711d1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────┐\n",
      "|      Narwhals DataFrame       |\n",
      "|-------------------------------|\n",
      "|shape: (111, 3)                |\n",
      "|┌───────────┬────────┬────────┐|\n",
      "|│ sample_id ┆ gene   ┆ burden │|\n",
      "|│ ---       ┆ ---    ┆ ---    │|\n",
      "|│ str       ┆ str    ┆ u32    │|\n",
      "|╞═══════════╪════════╪════════╡|\n",
      "|│ S036      ┆ GENE21 ┆ 2      │|\n",
      "|│ S038      ┆ GENE24 ┆ 1      │|\n",
      "|│ S039      ┆ GENE8  ┆ 1      │|\n",
      "|│ S035      ┆ GENE30 ┆ 1      │|\n",
      "|│ S012      ┆ GENE5  ┆ 1      │|\n",
      "|│ …         ┆ …      ┆ …      │|\n",
      "|│ S037      ┆ GENE24 ┆ 1      │|\n",
      "|│ S013      ┆ GENE25 ┆ 1      │|\n",
      "|│ S004      ┆ GENE19 ┆ 1      │|\n",
      "|│ S045      ┆ GENE27 ┆ 1      │|\n",
      "|│ S024      ┆ GENE23 ┆ 1      │|\n",
      "|└───────────┴────────┴────────┘|\n",
      "└───────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Per-sample, per-gene burden = count of rare LoF variants\n",
    "burden = (\n",
    "    variants_fe\n",
    "    .group_by([\"sample_id\", \"gene\"])\n",
    "    .agg(nw.len().alias(\"burden\"))\n",
    ")\n",
    "print(burden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c13eb8",
   "metadata": {},
   "source": [
    "## Pivot wider without engine-specific quirks\n",
    "Why unique: Polars and pandas pivot APIs differ; Narwhals smooths that over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8460d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────────────────────────────────────────────────┐\n",
      "|                             Narwhals DataFrame                             |\n",
      "|----------------------------------------------------------------------------|\n",
      "|shape: (5, 30)                                                              |\n",
      "|┌───────────┬───────┬───────┬────────┬───┬────────┬───────┬───────┬────────┐|\n",
      "|│ sample_id ┆ GENE3 ┆ GENE8 ┆ GENE12 ┆ … ┆ GENE11 ┆ GENE2 ┆ GENE6 ┆ GENE18 │|\n",
      "|│ ---       ┆ ---   ┆ ---   ┆ ---    ┆   ┆ ---    ┆ ---   ┆ ---   ┆ ---    │|\n",
      "|│ str       ┆ u32   ┆ u32   ┆ u32    ┆   ┆ u32    ┆ u32   ┆ u32   ┆ u32    │|\n",
      "|╞═══════════╪═══════╪═══════╪════════╪═══╪════════╪═══════╪═══════╪════════╡|\n",
      "|│ S026      ┆ 1     ┆ 1     ┆ 0      ┆ … ┆ 0      ┆ 1     ┆ 1     ┆ 0      │|\n",
      "|│ S009      ┆ 0     ┆ 1     ┆ 0      ┆ … ┆ 0      ┆ 0     ┆ 0     ┆ 0      │|\n",
      "|│ S043      ┆ 0     ┆ 0     ┆ 1      ┆ … ┆ 0      ┆ 0     ┆ 0     ┆ 0      │|\n",
      "|│ S045      ┆ 0     ┆ 1     ┆ 0      ┆ … ┆ 0      ┆ 0     ┆ 0     ┆ 0      │|\n",
      "|│ S006      ┆ 0     ┆ 0     ┆ 1      ┆ … ┆ 0      ┆ 0     ┆ 0     ┆ 0      │|\n",
      "|└───────────┴───────┴───────┴────────┴───┴────────┴───────┴───────┴────────┘|\n",
      "└────────────────────────────────────────────────────────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107832/3427752487.py:5: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.\n",
      "  burden_wide_native = burden_native.pivot(\n"
     ]
    }
   ],
   "source": [
    "# Wide sample × gene burden matrix\n",
    "#burden_wide = (\n",
    "#    burden\n",
    "#    .pivot(index=\"sample_id\", columns=\"gene\", values=\"burden\", fill_value=0)\n",
    "#    .sort(\"sample_id\")\n",
    "#)\n",
    "\n",
    "# Convert burden Narwhals DF to native polars\n",
    "burden_native = burden.to_native()\n",
    "\n",
    "# Use Polars pivot\n",
    "burden_wide_native = burden_native.pivot(\n",
    "    index=\"sample_id\",\n",
    "    columns=\"gene\",\n",
    "    values=\"burden\"\n",
    ").fill_null(0)  # fill missing cells with 0\n",
    "\n",
    "# Wrap back into Narwhals if you want to continue with Narwhals API\n",
    "burden_wide = nw.from_native(burden_wide_native)\n",
    "\n",
    "print(burden_wide.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "017c52c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has 'burden'? True\n",
      "n genes: 29 ; sample of genes: ['GENE18', 'GENE10', 'GENE30', 'GENE11', 'GENE25']\n",
      "expanded has first gene col? True\n"
     ]
    }
   ],
   "source": [
    "# genes is your Python list of gene names\n",
    "\n",
    "# build aggregations\n",
    "burden_wide = (\n",
    "    burden_expanded\n",
    "    .group_by(\"sample_id\")\n",
    "    .agg(**{g: nw.col(g).sum() for g in genes})   # kwargs is OK\n",
    "    .sort(\"sample_id\")\n",
    ")\n",
    "\n",
    "print(\"has 'burden'?\", \"burden\" in burden.columns)\n",
    "print(\"n genes:\", len(genes), \"; sample of genes:\", genes[:5])\n",
    "print(\"expanded has first gene col?\", genes[0] in burden_expanded.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874df96d",
   "metadata": {},
   "source": [
    "## Typed joins that “just work”\n",
    "Why unique: Joins often bite when dtypes (categorical vs string) differ across engines; Narwhals normalizes these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bc9bc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved design_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "# Join sample metadata for downstream modeling\n",
    "# Convert to native Polars DataFrame first\n",
    "design_native = design.to_native()\n",
    "\n",
    "# Save as CSV\n",
    "design_native.write_csv(\"./input_data/design_matrix.csv\")\n",
    "\n",
    "print(\"✅ Saved design_matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95913aa",
   "metadata": {},
   "source": [
    "## Optional: Lazy when available, eager when not (same code)\n",
    "If your backend is polars, Narwhals can route to lazy execution and push filters/aggregations down; with pandas, it executes eagerly—but your code doesn’t change.\n",
    "\n",
    "Why unique: You can prototype on pandas, then flip to polars for scale to get query planning and parallelism without touching the transformation code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b36b41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Conceptual toggle—Narwhals can map to a lazy plan where supported)\n",
    "variants_lazy = variants.lazy()   # becomes a no-op/eager facade on pandas\n",
    "pipeline = (\n",
    "    variants_lazy\n",
    "    .with_columns([is_rare_lof])\n",
    "    .filter(nw.col(\"is_rare_lof\"))\n",
    "    .group_by([\"sample_id\", \"gene\"])\n",
    "    .agg(nw.len().alias(\"burden\"))\n",
    ")\n",
    "result = pipeline.collect()       # polars: executes the optimized plan; pandas: returns materialized result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db7c9a",
   "metadata": {},
   "source": [
    "## Arrow/Parquet zero-copy interop (great for genomics)\n",
    "Why unique: In genomics, Parquet/Arrow are common for big tables (VCF→Parquet). Narwhals lets you stay in one API, avoiding manual conversions and engine-specific nuances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc264c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬────────┬────────────────────┬─────────┬─────────────┐\n",
      "│ sample_id ┆ gene   ┆ impact             ┆ AF      ┆ consequence │\n",
      "│ ---       ┆ ---    ┆ ---                ┆ ---     ┆ ---         │\n",
      "│ str       ┆ str    ┆ str                ┆ f64     ┆ str         │\n",
      "╞═══════════╪════════╪════════════════════╪═════════╪═════════════╡\n",
      "│ S039      ┆ GENE28 ┆ missense_variant   ┆ 0.07361 ┆ moderate    │\n",
      "│ S029      ┆ GENE18 ┆ frameshift_variant ┆ 0.00102 ┆ high        │\n",
      "│ S015      ┆ GENE4  ┆ stop_gained        ┆ 0.00097 ┆ high        │\n",
      "│ S043      ┆ GENE13 ┆ missense_variant   ┆ 0.04071 ┆ moderate    │\n",
      "│ S008      ┆ GENE4  ┆ missense_variant   ┆ 0.05094 ┆ moderate    │\n",
      "└───────────┴────────┴────────────────────┴─────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "def read_parquet_narwhals(path: str, backend: str = \"polars\"):\n",
    "    if backend == \"polars\":\n",
    "        import polars as pl\n",
    "        native = pl.read_parquet(path)\n",
    "    elif backend == \"pandas\":\n",
    "        import pandas as pd\n",
    "        native = pd.read_parquet(path)  # engine='pyarrow' if your setup requires it\n",
    "    else:\n",
    "        raise ValueError(\"backend must be 'polars' or 'pandas'\")\n",
    "    return nw.from_native(native)\n",
    "\n",
    "variants = read_parquet_narwhals(\"./input_data/cohort_variants.parquet\", backend=\"polars\")\n",
    "variants = variants.with_columns([nw.col(\"AF\").cast(nw.Float64)])\n",
    "print(variants.to_native().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc43766",
   "metadata": {},
   "source": [
    "## Window ops without rewriting (per-sample QC example)\n",
    "Why unique: Uniform window/over semantics; no need to learn/set up two different rolling/grouped transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4a8880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌───────────┬───────────────────┐\n",
      "│ sample_id ┆ n_variants_sample │\n",
      "│ ---       ┆ ---               │\n",
      "│ str       ┆ u32               │\n",
      "╞═══════════╪═══════════════════╡\n",
      "│ S001      ┆ 24                │\n",
      "│ S002      ┆ 21                │\n",
      "│ S003      ┆ 22                │\n",
      "│ S004      ┆ 16                │\n",
      "│ S005      ┆ 23                │\n",
      "└───────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "qc = (\n",
    "    variants\n",
    "    .group_by(\"sample_id\")\n",
    "    .agg(nw.len().alias(\"n_variants_sample\"))\n",
    "    .sort(\"sample_id\")\n",
    ")\n",
    "\n",
    "print(qc.to_native().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002246e3",
   "metadata": {},
   "source": [
    "Why this shows Narwhals’ uniqueness \n",
    "\n",
    "- Write once, scale later: Prototype on a laptop with pandas; switch to polars for large cohorts—all transformations stay identical.\n",
    "\n",
    "- Declarative expressions: Clear, composable feature engineering without backend-specific .apply functions.\n",
    "\n",
    "- Robust IO & interop: CSV/TSV now, Arrow/Parquet later—same API. Great fit for variant tables, gene counts, cell metadata, etc.\n",
    "\n",
    "- Consistent wide-table shaping: Pivots, joins, groupbys, and window ops behave uniformly—critical in pipelines that hop between wide (sample×gene) and long (tidy) layouts.\n",
    "\n",
    "- Optional laziness: When the backend supports it (polars), you get optimization and pushdown “for free.”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narwhals-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
